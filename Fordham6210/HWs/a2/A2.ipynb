{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from urllib.request import urlopen\n",
    "import numpy as np\n",
    "import warnings\n",
    "import os \n",
    "import re\n",
    "\n",
    "html = urlopen('https://storm.cis.fordham.edu/~yli/data/MyShakespeare.txt').read().decode('utf-8','ignore')\n",
    "soup = BeautifulSoup(html, features='lxml')\n",
    "all_href = soup.find_all('p')\n",
    "l = re.sub(r'\\r\\n\\r\\n','[P]',str(all_href))\n",
    "l = re.sub(r'<.*?>','',l)\n",
    "l = re.sub(r'\\r\\n',' ',l)\n",
    "l = re.sub(r'\\[P\\]','\\r\\n\\r\\n',l)\n",
    "\n",
    "with open('data.txt','w')as f:\n",
    "    f.write(l[1:-1])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "SPECIAL_WORDS = {'PADDING': '<PAD>'}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from collections import Counter\n",
    "class NgramModel(object):\n",
    "    def __init__(self,n = 3):\n",
    "        super(NgramModel,self).__init__()\n",
    "        self.n = n # Tell me how many gram you want?\n",
    "        self.create_lookup_tables = self.create_lookup_tables\n",
    "        self.token_lookup = self._token_lookup()\n",
    "        self.vocab_to_int = None\n",
    "        self.int_to_vocab = None\n",
    "        self.word_counter = None\n",
    "        self.int_text = None\n",
    "        self.corpus = None\n",
    "        self.ngram_matrix = None\n",
    "        self.gram_counter = None\n",
    "        self.ngram_1matrix = None\n",
    "        assert self.n > 1, \"N should larger than 1 !!!!!\"\n",
    "        \n",
    "    \n",
    "    def load_data(self,path):\n",
    "        input_file = os.path.join(path)\n",
    "        with open(input_file, \"r\") as f:\n",
    "            data = f.read()\n",
    "        return data    \n",
    "    \n",
    "    def _token_lookup(self):\n",
    "        answer = {'.' : '||period||',\n",
    "                  ',' : '||comma||',\n",
    "                  '\"' : '||quotation_mark||',\n",
    "                  ';' : '||semicolon||',\n",
    "                  '!' : '||exclamation_mark||',\n",
    "                  '?' : '||question_mark||',\n",
    "                  '(' : '||left_Parentheses||',\n",
    "                  ')' : '||right_Parentheses||',\n",
    "                  #'\\n': '||return||',\n",
    "                  '-' : '||dash||'}\n",
    "        return answer\n",
    "    \n",
    "    def update(self,text):\n",
    "        text = self.load_data(text)\n",
    "        text = self.preprocessing(text).lower()\n",
    "        self.corpus = ['<START> '* (self.n-1) + t + ' <END>' * (self.n-1) for t in text.split('\\n\\n')]\n",
    "        \n",
    "        text = text.split()\n",
    "        self.word_counter = Counter(text)\n",
    "        self.vocab_to_int, self.int_to_vocab = self.create_lookup_tables(text + list(SPECIAL_WORDS.values()))\n",
    "        self.int_text = [self.vocab_to_int[word] for word in text]\n",
    "        \n",
    "        \n",
    "    def preprocessing(self,text):\n",
    "        for key, token in self.token_lookup.items():\n",
    "            text = text.replace(key, ' {} '.format(token))\n",
    "        return text\n",
    "    \n",
    "    def create_lookup_tables(self,text):\n",
    "        vocab_to_int = { v:i+2 for i,v in enumerate(set(text))}\n",
    "        vocab_to_int['<START>'] = 0\n",
    "        vocab_to_int['<end>'] = 1\n",
    "        int_to_vocab = { v:k for k,v in vocab_to_int.items()}\n",
    "        # return tuple\n",
    "        return (vocab_to_int, int_to_vocab)\n",
    "        \n",
    "    \n",
    "    def get_vocab(self):\n",
    "        return self.vocab_to_int\n",
    "    \n",
    "    def size_vocab(self):\n",
    "        return len(self.vocab_to_int)\n",
    "    \n",
    "    def get_gram(self):\n",
    "        self._n_1gram()\n",
    "        m = []\n",
    "        for i in self.corpus:\n",
    "            try:\n",
    "                if len(i.split()) < self.n:\n",
    "                    ng = self.pad(i.split)\n",
    "                    m.append(tuple(ng))\n",
    "                else:\n",
    "                    for j in range(len(i.split())-self.n):\n",
    "                        ng = i.split()[j:j+self.n]\n",
    "                        m.append(tuple(ng))\n",
    "            except:\n",
    "                KeyboardInterrupt\n",
    "        self.ngram_matrix = m\n",
    "        \n",
    "    def _n_1gram(self):\n",
    "        m = []\n",
    "        for i in self.corpus:\n",
    "            try:\n",
    "                if len(i.split()) < self.n:\n",
    "                    ng = self.pad(i.split)\n",
    "                    m.append(tuple(ng))\n",
    "                else:\n",
    "                    for j in range(len(i.split())-self.n+1):\n",
    "                        ng = i.split()[j:j+self.n-1]\n",
    "                        m.append(tuple(ng))\n",
    "            except:\n",
    "                KeyboardInterrupt\n",
    "        self.ngram_1matrix = m\n",
    "        \n",
    "    \n",
    "    def len_text(self):\n",
    "        return len(self.text.split())-2\n",
    "    \n",
    "    def len_ngram(self):\n",
    "        return len(self.ngram_matrix)\n",
    "    \n",
    "    def word_freq(self,word):\n",
    "        print(self.counter[word])\n",
    "            \n",
    "        \n",
    "    def pad(self,text,):\n",
    "        l = len(text)\n",
    "        n = self.n-l\n",
    "        for _ in range(n):\n",
    "            text.append('<PAD>')\n",
    "        return text\n",
    "    \n",
    "    def len_gram(self):\n",
    "        return len(self.ngram_matrix)\n",
    "    \n",
    "    def ngram_freq(self,gram):\n",
    "        gram = self.preprocessing(gram)\n",
    "        test = [ i for i in gram.lower().split()]\n",
    "        assert len(test) == self.n, 'It seems the length of you input is not match !!'\n",
    "        try:\n",
    "            if self.gram_counter == None:\n",
    "                self.gram_counter = Counter(self.ngram_matrix)\n",
    "            \n",
    "            if self.gram_counter[tuple(test)] == 0 :\n",
    "                print('Come on, we dont have these combo !!')\n",
    "                pro = 1/(self.size_vocab()*2)\n",
    "                print('Probobility is {a}'.format(a=pro))\n",
    "            else:                     \n",
    "                #print(self.gram_counter[tuple(test)])\n",
    "                return self.gram_counter[tuple(test)]\n",
    "        except:\n",
    "            KeyboardInterrupt\n",
    "            \n",
    "    def n_1gram_freq(self,gram):\n",
    "        gram = self.preprocessing(gram)\n",
    "        test = [ i for i in gram.lower().split()]\n",
    "        test.pop()\n",
    "        try:\n",
    "            gram_counter = Counter(self.ngram_1matrix)\n",
    "            \n",
    "            if gram_counter[tuple(test)] == 0 :\n",
    "                print('Come on, we dont have these combo !!')\n",
    "            else:                     \n",
    "                #print(self.gram_counter[tuple(test)])\n",
    "                return gram_counter[tuple(test)]\n",
    "        except:\n",
    "            KeyboardInterrupt\n",
    "            \n",
    "    def get_pro(self,ngram):\n",
    "        return self.ngram_freq(ngram)/self.ngram_freq(ngram)\n",
    "        \n",
    "                \n",
    "                \n",
    "    def text_generate(self,gram, min_length, max_length):\n",
    "        gram = self.preprocessing(gram)\n",
    "        test = [ i for i in gram.lower().split()]\n",
    "        #print(test)\n",
    "        assert len(test) >= self.n -1, 'You are too short to gen !!!!'\n",
    "        while len(test) <= max_length:\n",
    "            gen = tuple(test[-2:])\n",
    "            #print(gen)\n",
    "            test.append(self.findCondition(gen))\n",
    "            if self.findCondition(gen) == '<END>':\n",
    "                break\n",
    "            \n",
    "        return self.parse(test)\n",
    "        \n",
    "    def findCondition(self,n_1gram):\n",
    "        candidate = [i for i in self.ngram_matrix if i[:self.n-1] == n_1gram]\n",
    "        #print(candidate)\n",
    "        c = Counter(candidate)\n",
    "        print(len(c.most_common(1)))\n",
    "        try:\n",
    "            if len(c.most_common(1))>0:\n",
    "                next_word = c.most_common(1)[0][0][-1]\n",
    "                return next_word\n",
    "            return\n",
    "        except:\n",
    "            KeyboardInterrupt\n",
    "        \n",
    "    def parse(self,text):\n",
    "        text = \" \".join(text)\n",
    "        for token, key in self.token_lookup.items():\n",
    "            text = text.replace(key, ' {} '.format(token))\n",
    "        return \" \".join(re.findall(r'.+(?=\\s\\<END\\>)',text)[0].split())    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "ng = NgramModel(3)\n",
    "ng.update('data.txt')\n",
    "ng.get_gram()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ng.ngram_freq('members, the')\n",
    "ng.get_pro('members, the')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "sequence item 2: expected str instance, NoneType found",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-207-0e24cbea630f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mng\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext_generate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Alex is '\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-204-7cd0e19dc4cc>\u001b[0m in \u001b[0;36mtext_generate\u001b[0;34m(self, gram, min_length, max_length)\u001b[0m\n\u001b[1;32m    170\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 172\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    173\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfindCondition\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mn_1gram\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-204-7cd0e19dc4cc>\u001b[0m in \u001b[0;36mparse\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m    186\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 188\u001b[0;31m         \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\" \"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    189\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtoken\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoken_lookup\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m             \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m' {} '\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: sequence item 2: expected str instance, NoneType found"
     ]
    }
   ],
   "source": [
    "ng.text_generate('Alex is ',10,20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
